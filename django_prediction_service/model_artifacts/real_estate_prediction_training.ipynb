{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3544858-39dc-473b-bdaf-e7020f450753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression # Or RandomForestRegressor, XGBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "print(\"Libraries imported successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e02f30e-c7d4-47ae-80ba-06ddfb8b8d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from ./residential_property_prices.csv. Shape: (332096, 32)\n",
      "\n",
      "First 5 rows of the dataset:\n",
      "               Property_Name  Property_id Property_type     Property_status  \\\n",
      "0               Arkiton Luxe     15446514     Apartment  Under Construction   \n",
      "1  Keshav Akshar Ocean Pearl     15367414     Apartment  Under Construction   \n",
      "2            Vishwa Opulence     14683118     Apartment       Ready to move   \n",
      "3              Satyam Sarjan      5476295     Apartment       Ready to move   \n",
      "4           Navkar Sunflower     15477040     Apartment  Under Construction   \n",
      "\n",
      "  Price_per_unit_area   Posted_On  \\\n",
      "0               4,285   1 day ago   \n",
      "1               7,000  2 days ago   \n",
      "2               5,752  2 days ago   \n",
      "3               2,486  5 days ago   \n",
      "4               5,324  8 days ago   \n",
      "\n",
      "                                         Project_URL   builder_id  \\\n",
      "0  https://www.makaan.com/ahmedabad/arkiton-life-...  100563465.0   \n",
      "1  https://www.makaan.com/ahmedabad/keshav-naraya...  100009433.0   \n",
      "2  https://www.makaan.com/ahmedabad/vishwa-develo...  100207731.0   \n",
      "3  https://www.makaan.com/ahmedabad/satyam-develo...     101303.0   \n",
      "4  https://www.makaan.com/ahmedabad/navkar-buildc...    1484209.0   \n",
      "\n",
      "                  Builder_name Property_building_status  ...  is_furnished  \\\n",
      "0           Arkiton life Space                   ACTIVE  ...   Unfurnished   \n",
      "1         Keshav Narayan Group                   ACTIVE  ...   Unfurnished   \n",
      "2  Vishwa Developers Ahmedabad                   ACTIVE  ...   Unfurnished   \n",
      "3            Satyam Developers                   ACTIVE  ...   Unfurnished   \n",
      "4    Navkar Buildcon Ahmedabad                   ACTIVE  ...   Unfurnished   \n",
      "\n",
      "  listing_domain_score is_plot  is_RERA_registered is_Apartment  \\\n",
      "0                  4.0   False                True         True   \n",
      "1                  4.0   False                True         True   \n",
      "2                  4.0   False               False         True   \n",
      "3                  4.0   False               False         True   \n",
      "4                  4.0   False                True         True   \n",
      "\n",
      "   is_ready_to_move  is_commercial_Listing is_PentaHouse is_studio  \\\n",
      "0             False                  False         False     False   \n",
      "1             False                  False         False     False   \n",
      "2              True                  False         False     False   \n",
      "3              True                  False         False     False   \n",
      "4             False                  False         False     False   \n",
      "\n",
      "   Listing_Category  \n",
      "0              sell  \n",
      "1              sell  \n",
      "2              sell  \n",
      "3              sell  \n",
      "4              sell  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Define Data Paths and Load Data\n",
    "# IMPORTANT: Adjust 'DATA_PATH' if your CSV is in a different location\n",
    "DATA_PATH = './residential_property_prices.csv'\n",
    "\n",
    "try:\n",
    "    # Try 'latin1' first, it's a common fallback. If that doesn't work, try 'cp1252'.\n",
    "    df = pd.read_csv(DATA_PATH, encoding='latin1')\n",
    "    # If latin1 fails, try:\n",
    "    # df = pd.read_csv(DATA_PATH, encoding='cp1252')\n",
    "\n",
    "    print(f\"Data loaded successfully from {DATA_PATH}. Shape: {df.shape}\")\n",
    "    print(\"\\nFirst 5 rows of the dataset:\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Data file not found at {DATA_PATH}. Please ensure the CSV is in the correct directory.\")\n",
    "    # Exit or provide a dummy DataFrame for testing if crucial\n",
    "except UnicodeDecodeError as e:\n",
    "    print(f\"UnicodeDecodeError: Failed to read CSV with specified encoding. Try a different encoding. Error: {e}\")\n",
    "    # Consider manually inspecting the file encoding if multiple attempts fail\n",
    "    exit() # Or handle the error differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb2f9396-f5a7-4953-9c33-24820ac4c305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 332096 entries, 0 to 332095\n",
      "Data columns (total 32 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   Property_Name             217826 non-null  object \n",
      " 1   Property_id               332096 non-null  int64  \n",
      " 2   Property_type             332096 non-null  object \n",
      " 3   Property_status           271654 non-null  object \n",
      " 4   Price_per_unit_area       332096 non-null  object \n",
      " 5   Posted_On                 332096 non-null  object \n",
      " 6   Project_URL               332096 non-null  object \n",
      " 7   builder_id                149978 non-null  float64\n",
      " 8   Builder_name              149978 non-null  object \n",
      " 9   Property_building_status  332096 non-null  object \n",
      " 10  City_id                   332096 non-null  int64  \n",
      " 11  City_name                 332096 non-null  object \n",
      " 12  No_of_BHK                 332096 non-null  object \n",
      " 13  Locality_ID               332096 non-null  int64  \n",
      " 14  Locality_Name             332094 non-null  object \n",
      " 15  Longitude                 332096 non-null  float64\n",
      " 16  Latitude                  332096 non-null  float64\n",
      " 17  Price                     332096 non-null  object \n",
      " 18  Size                      332096 non-null  object \n",
      " 19  Sub_urban_ID              332096 non-null  int64  \n",
      " 20  Sub_urban_name            332096 non-null  object \n",
      " 21  description               332095 non-null  object \n",
      " 22  is_furnished              332096 non-null  object \n",
      " 23  listing_domain_score      332096 non-null  float64\n",
      " 24  is_plot                   332096 non-null  bool   \n",
      " 25  is_RERA_registered        332096 non-null  bool   \n",
      " 26  is_Apartment              332096 non-null  bool   \n",
      " 27  is_ready_to_move          332096 non-null  bool   \n",
      " 28  is_commercial_Listing     332096 non-null  bool   \n",
      " 29  is_PentaHouse             332096 non-null  bool   \n",
      " 30  is_studio                 332096 non-null  bool   \n",
      " 31  Listing_Category          332096 non-null  object \n",
      "dtypes: bool(7), float64(4), int64(4), object(17)\n",
      "memory usage: 65.6+ MB\n",
      "\n",
      "Descriptive Statistics (Numerical Columns):\n",
      "        Property_id    builder_id        City_id    Locality_ID  \\\n",
      "count  3.320960e+05  1.499780e+05  332096.000000  332096.000000   \n",
      "mean   1.319382e+07  1.108900e+07      12.137861   63082.944775   \n",
      "std    2.533792e+06  3.100384e+07       7.270491   26246.913783   \n",
      "min    5.000114e+06  1.000020e+05       1.000000   50001.000000   \n",
      "25%    1.244466e+07  1.006780e+05       5.000000   50378.000000   \n",
      "50%    1.419741e+07  1.034750e+05      12.000000   51893.000000   \n",
      "75%    1.509555e+07  6.547740e+05      18.000000   60223.000000   \n",
      "max    1.558147e+07  1.007295e+08      23.000000  173237.000000   \n",
      "\n",
      "           Longitude       Latitude   Sub_urban_ID  listing_domain_score  \n",
      "count  332096.000000  332096.000000  332096.000000         332096.000000  \n",
      "mean       77.626544      19.761817   10140.731770              4.005565  \n",
      "std         4.163027       5.311124     197.784494              0.124058  \n",
      "min        23.526030       8.403612   10003.000000              4.000000  \n",
      "25%        73.033897      13.580514   10040.000000              4.000000  \n",
      "50%        77.666607      19.165211   10071.000000              4.000000  \n",
      "75%        80.157450      23.048038   10226.000000              4.000000  \n",
      "max        88.861885      87.360603   11618.000000              9.107140  \n",
      "\n",
      "Missing values per column (Top 10 with most NaNs):\n",
      "builder_id             182118\n",
      "Builder_name           182118\n",
      "Property_Name          114270\n",
      "Property_status         60442\n",
      "Locality_Name               2\n",
      "description                 1\n",
      "Property_type               0\n",
      "Price_per_unit_area         0\n",
      "Project_URL                 0\n",
      "Posted_On                   0\n",
      "dtype: int64\n",
      "\n",
      "Unique values in key categorical columns:\n",
      "- Property_type: 5 unique values\n",
      "Property_type\n",
      "Apartment            188922\n",
      "Residential Plot      93765\n",
      "Independent Floor     22554\n",
      "Independent House     13553\n",
      "Villa                 13302\n",
      "Name: count, dtype: int64\n",
      "- Property_status: 2 unique values\n",
      "Property_status\n",
      "Ready to move         179800\n",
      "Under Construction     91854\n",
      "Name: count, dtype: int64\n",
      "- Listing_Category: 1 unique values\n",
      "Listing_Category\n",
      "sell    332096\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Initial Data Info and Summary\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nDescriptive Statistics (Numerical Columns):\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing values per column (Top 10 with most NaNs):\")\n",
    "print(df.isnull().sum().sort_values(ascending=False).head(10))\n",
    "\n",
    "print(\"\\nUnique values in key categorical columns:\")\n",
    "# Check 'Property_type', 'Property_status', 'City', 'Furnishing_status', 'Listing_Category'\n",
    "for col in ['Property_type', 'Property_status', 'City', 'Furnishing_status', 'Listing_Category']:\n",
    "    if col in df.columns:\n",
    "        print(f\"- {col}: {df[col].nunique()} unique values\")\n",
    "        print(df[col].value_counts().head()) # Show top values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a613e260-f17d-4790-a477-d8df4f4bc47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after renaming: ['City', 'BHK', 'Super_Builtup_Area', 'Furnishing_status', 'Property_type', 'Price_in_cr']\n",
      "After cleaning: (0, 6)\n",
      "\n",
      "Final features (X) used for training:\n",
      "['City_Encoded', 'BHK', 'Super_Builtup_Area', 'Furnishing_status_Encoded']\n",
      "Shape of X: (0, 4), Shape of y: (0,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 4.1: Feature Selection and Renaming ---\n",
    "\n",
    "# Define new mapping for your dataset\n",
    "features_raw = ['City_name', 'No_of_BHK', 'Size', 'is_furnished', 'Property_type', 'Price']\n",
    "mapped_columns = {\n",
    "    'City_name': 'City',\n",
    "    'No_of_BHK': 'BHK',\n",
    "    'Size': 'Super_Builtup_Area',\n",
    "    'is_furnished': 'Furnishing_status',\n",
    "    'Property_type': 'Property_type',\n",
    "    'Price': 'Price_in_cr'  # Will convert to crore as float\n",
    "}\n",
    "\n",
    "# Ensure existence of all necessary columns\n",
    "for col in features_raw:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Error: Column '{col}' not found!\")\n",
    "        exit()\n",
    "\n",
    "# Rename columns for simplicity\n",
    "df_selected = df[features_raw].rename(columns=mapped_columns).copy()\n",
    "print(f\"Columns after renaming: {df_selected.columns.tolist()}\")\n",
    "\n",
    "# --- 4.2: Data Cleaning ---\n",
    "\n",
    "# 1. Clean BHK: Convert to int\n",
    "df_selected['BHK'] = pd.to_numeric(df_selected['BHK'], errors='coerce')\n",
    "\n",
    "# 2. Clean Super_Builtup_Area: Extract numeric value from \"1200 sqft\" etc.\n",
    "df_selected['Super_Builtup_Area'] = (\n",
    "    df_selected['Super_Builtup_Area']\n",
    "    .str.extract(r'(\\d+\\.?\\d*)')    # Extract numeric part\n",
    "    .astype(float)\n",
    ")\n",
    "\n",
    "# 3. Clean Price_in_cr: Convert '65 L', '1.2 Cr', etc. into float (crores)\n",
    "def price_to_crore(value):\n",
    "    value = str(value).strip().replace(',', '')  # remove potential commas\n",
    "    if 'Cr' in value:\n",
    "        return float(value.replace('Cr', '').strip())\n",
    "    elif 'L' in value:\n",
    "        return float(value.replace('L', '').strip()) / 100\n",
    "    else:\n",
    "        try:\n",
    "            return float(value) / 100  # Assume Lacs by default\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "df_selected['Price_in_cr'] = df_selected['Price_in_cr'].apply(price_to_crore)\n",
    "\n",
    "# --- 4.3: Drop NA rows in essential columns ---\n",
    "df_cleaned = df_selected.dropna().copy()\n",
    "print(f\"After cleaning: {df_cleaned.shape}\")\n",
    "\n",
    "# --- 4.4: Feature Encoding ---\n",
    "\n",
    "# City Encoding\n",
    "location_encoder = LabelEncoder()\n",
    "df_cleaned['City_Encoded'] = location_encoder.fit_transform(df_cleaned['City'])\n",
    "\n",
    "# Furnishing_status Encoding\n",
    "furnishing_encoder = LabelEncoder()\n",
    "df_cleaned['Furnishing_status_Encoded'] = furnishing_encoder.fit_transform(df_cleaned['Furnishing_status'])\n",
    "\n",
    "# One-hot encode Property_type (drop_first=True to avoid redundancy)\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=['Property_type'], prefix='PropertyType', drop_first=True)\n",
    "\n",
    "# --- 4.5: FINAL FEATURE SET (X) AND TARGET (y) ---\n",
    "\n",
    "final_features = [\n",
    "    'City_Encoded',\n",
    "    'BHK',\n",
    "    'Super_Builtup_Area',\n",
    "    'Furnishing_status_Encoded',\n",
    "]\n",
    "property_type_cols = [col for col in df_cleaned.columns if col.startswith('PropertyType_')]\n",
    "final_features.extend(property_type_cols)\n",
    "\n",
    "X = df_cleaned[final_features]\n",
    "y = df_cleaned['Price_in_cr'] * 1e7  # Back to actual price in INR for ML training\n",
    "\n",
    "print(\"\\nFinal features (X) used for training:\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e818d105-ca74-4cbe-bcf1-a8c289a043ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape after selecting and initial renaming: (332096, 6)\n",
      "Columns after initial renaming:\n",
      "['City', 'BHK', 'Super_Builtup_Area', 'Furnishing_status', 'Property_type', 'Original_Price_Raw']\n",
      "\n",
      "'Price_Cleaned_INR' created (original vs cleaned):\n",
      "  Original_Price_Raw  Price_Cleaned_INR\n",
      "0          75,00,000          7500000.0\n",
      "1        2,36,88,000         23688000.0\n",
      "2        1,32,00,840         13200840.0\n",
      "3          22,83,000          2283000.0\n",
      "4          93,71,000          9371000.0\n",
      "\n",
      "'Super_Builtup_Area_Cleaned' created (original vs cleaned):\n",
      "  Super_Builtup_Area  Super_Builtup_Area_Cleaned\n",
      "0        1,750 sq ft                      1750.0\n",
      "1        3,384 sq ft                      3384.0\n",
      "2        2,295 sq ft                      2295.0\n",
      "3          918 sq ft                       918.0\n",
      "4        1,760 sq ft                      1760.0\n",
      "\n",
      "'BHK_Cleaned' created (original vs cleaned):\n",
      "     BHK  BHK_Cleaned\n",
      "0  3 BHK          3.0\n",
      "1  4 BHK          4.0\n",
      "2  3 BHK          3.0\n",
      "3  2 BHK          2.0\n",
      "4  3 BHK          3.0\n",
      "\n",
      "DataFrame shape after cleaning and dropping NaNs: (332096, 9)\n",
      "\n",
      "City Encoding classes (first 5):\n",
      "['Ahmedabad' 'Bangalore' 'Chennai' 'Delhi' 'Hyderabad']\n",
      "\n",
      "Furnishing Status Encoding classes:\n",
      "['Furnished' 'Semi-Furnished' 'Unfurnished']\n",
      "\n",
      "After One-Hot Encoding Property_type (first 5 rows with new columns):\n",
      "   PropertyType_Independent Floor  PropertyType_Independent House  \\\n",
      "0                           False                           False   \n",
      "1                           False                           False   \n",
      "2                           False                           False   \n",
      "3                           False                           False   \n",
      "4                           False                           False   \n",
      "\n",
      "   PropertyType_Residential Plot  PropertyType_Villa  \n",
      "0                          False               False  \n",
      "1                          False               False  \n",
      "2                          False               False  \n",
      "3                          False               False  \n",
      "4                          False               False  \n",
      "\n",
      "Final features (X) used for training (and expected in Django prediction):\n",
      "['City_Encoded', 'BHK_Cleaned', 'Super_Builtup_Area_Cleaned', 'Furnishing_status_Encoded', 'PropertyType_Independent Floor', 'PropertyType_Independent House', 'PropertyType_Residential Plot', 'PropertyType_Villa']\n",
      "Shape of X: (332096, 8), Shape of y: (332096,)\n",
      "\n",
      "Model expects features in this order: ['City_Encoded', 'BHK_Cleaned', 'Super_Builtup_Area_Cleaned', 'Furnishing_status_Encoded', 'PropertyType_Independent Floor', 'PropertyType_Independent House', 'PropertyType_Residential Plot', 'PropertyType_Villa']\n"
     ]
    }
   ],
   "source": [
    "# Cell 4: Data Cleaning and Feature Engineering (Corrected - Removed 'Bathroom' column)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# --- 4.1: Feature Selection and Renaming ---\n",
    "# Based on your df.info() and df.head() output.\n",
    "features_raw = [\n",
    "    'City_name',\n",
    "    'No_of_BHK',\n",
    "    'Size',\n",
    "    # 'Bathroom', # REMOVED: This column is not in your dataset as confirmed\n",
    "    'is_furnished',\n",
    "    'Property_type',\n",
    "    'Price'              # This is your target column\n",
    "]\n",
    "\n",
    "# Ensure existence of all necessary columns\n",
    "for col in features_raw:\n",
    "    if col not in df.columns:\n",
    "        print(f\"Error: Column '{col}' not found in the dataset! Please check your CSV column names.\")\n",
    "        exit()\n",
    "\n",
    "# Create a copy to avoid SettingWithCopyWarning\n",
    "df_cleaned = df[features_raw].copy()\n",
    "\n",
    "# Rename columns for simplicity and consistency with common ML terms\n",
    "df_cleaned.rename(columns={\n",
    "    'City_name': 'City',\n",
    "    'No_of_BHK': 'BHK',\n",
    "    'Size': 'Super_Builtup_Area',\n",
    "    'is_furnished': 'Furnishing_status',\n",
    "    'Price': 'Original_Price_Raw' # Keep original Price raw for reference during cleaning\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"DataFrame shape after selecting and initial renaming: {df_cleaned.shape}\")\n",
    "print(\"Columns after initial renaming:\")\n",
    "print(df_cleaned.columns.tolist())\n",
    "\n",
    "\n",
    "# --- 4.2: Data Cleaning and Type Conversion ---\n",
    "\n",
    "# 1. Clean 'Price' column (Object type -> Numeric)\n",
    "def clean_price(price_str):\n",
    "    price_str = str(price_str).strip().replace('â‚¹', '').replace(',', '').lower()\n",
    "    if 'cr' in price_str:\n",
    "        return float(price_str.replace('cr', '').strip()) * 10000000\n",
    "    elif 'l' in price_str or 'lac' in price_str:\n",
    "        return float(price_str.replace('l', '').replace('ac', '').strip()) * 100000\n",
    "    elif 'k' in price_str:\n",
    "        return float(price_str.replace('k', '').strip()) * 1000\n",
    "    else:\n",
    "        try:\n",
    "            return float(price_str)\n",
    "        except ValueError:\n",
    "            return np.nan\n",
    "\n",
    "df_cleaned['Price_Cleaned_INR'] = df_cleaned['Original_Price_Raw'].apply(clean_price)\n",
    "print(\"\\n'Price_Cleaned_INR' created (original vs cleaned):\")\n",
    "print(df_cleaned[['Original_Price_Raw', 'Price_Cleaned_INR']].head())\n",
    "\n",
    "\n",
    "# 2. Clean 'Super_Builtup_Area' (Object type -> Numeric)\n",
    "def clean_area_sqft(area_str):\n",
    "    area_str = str(area_str).strip().lower().replace('sq.ft', '').replace('sqft', '').replace('sq ft', '').replace(',', '')\n",
    "    try:\n",
    "        return float(area_str)\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df_cleaned['Super_Builtup_Area_Cleaned'] = df_cleaned['Super_Builtup_Area'].apply(clean_area_sqft)\n",
    "print(\"\\n'Super_Builtup_Area_Cleaned' created (original vs cleaned):\")\n",
    "print(df_cleaned[['Super_Builtup_Area', 'Super_Builtup_Area_Cleaned']].head())\n",
    "\n",
    "\n",
    "# 3. Clean 'BHK' (Object type -> Numeric)\n",
    "def clean_bhk_numeric(bhk_str):\n",
    "    bhk_str = str(bhk_str).strip().lower()\n",
    "    if 'rk' in bhk_str:\n",
    "        return 0.5\n",
    "    try:\n",
    "        return int(float(bhk_str.replace('bhk', '').strip()))\n",
    "    except ValueError:\n",
    "        return np.nan\n",
    "\n",
    "df_cleaned['BHK_Cleaned'] = df_cleaned['BHK'].apply(clean_bhk_numeric)\n",
    "print(\"\\n'BHK_Cleaned' created (original vs cleaned):\")\n",
    "print(df_cleaned[['BHK', 'BHK_Cleaned']].head())\n",
    "\n",
    "# --- 4.3: Handle NaNs in crucial cleaned columns ---\n",
    "# Drop rows where cleaning resulted in NaN in our critical features or target\n",
    "# Removed 'Bathroom' from this subset as well\n",
    "df_cleaned.dropna(subset=['Price_Cleaned_INR', 'Super_Builtup_Area_Cleaned', 'BHK_Cleaned'], inplace=True)\n",
    "\n",
    "# Convert to appropriate integer types where applicable after dropping NaNs\n",
    "df_cleaned['BHK_Cleaned'] = df_cleaned['BHK_Cleaned'].astype(int)\n",
    "# Removed: df_cleaned['Bathroom'] = df_cleaned['Bathroom'].astype(int)\n",
    "\n",
    "\n",
    "print(f\"\\nDataFrame shape after cleaning and dropping NaNs: {df_cleaned.shape}\")\n",
    "\n",
    "# --- 4.4: Feature Encoding ---\n",
    "\n",
    "# City Encoding (LabelEncoder)\n",
    "location_encoder = LabelEncoder()\n",
    "df_cleaned['City_Encoded'] = location_encoder.fit_transform(df_cleaned['City'])\n",
    "print(\"\\nCity Encoding classes (first 5):\")\n",
    "if len(location_encoder.classes_) > 5:\n",
    "    print(location_encoder.classes_[:5])\n",
    "else:\n",
    "    print(location_encoder.classes_)\n",
    "\n",
    "\n",
    "# Furnishing_status Encoding (LabelEncoder)\n",
    "furnishing_encoder = LabelEncoder()\n",
    "df_cleaned['Furnishing_status_Encoded'] = furnishing_encoder.fit_transform(df_cleaned['Furnishing_status'])\n",
    "print(\"\\nFurnishing Status Encoding classes:\")\n",
    "print(furnishing_encoder.classes_)\n",
    "\n",
    "# Property_type (One-Hot Encoding)\n",
    "df_cleaned = pd.get_dummies(df_cleaned, columns=['Property_type'], prefix='PropertyType', drop_first=True)\n",
    "print(\"\\nAfter One-Hot Encoding Property_type (first 5 rows with new columns):\")\n",
    "dummy_cols_sample = [col for col in df_cleaned.columns if col.startswith('PropertyType_')]\n",
    "if len(dummy_cols_sample) > 5:\n",
    "    print(df_cleaned[dummy_cols_sample[:5]].head())\n",
    "else:\n",
    "    print(df_cleaned[dummy_cols_sample].head())\n",
    "\n",
    "\n",
    "# --- 4.5: FINAL FEATURE SET (X) AND TARGET (y) ---\n",
    "\n",
    "# Define the final features for X based on cleaned and encoded DataFrame\n",
    "final_features = [\n",
    "    'City_Encoded',\n",
    "    'BHK_Cleaned',\n",
    "    'Super_Builtup_Area_Cleaned', # Use the cleaned Size column\n",
    "    # 'Bathroom', # REMOVED: This column is not in your dataset\n",
    "    'Furnishing_status_Encoded',\n",
    "]\n",
    "# Add dynamically created one-hot encoded columns for Property_type\n",
    "property_type_cols = [col for col in df_cleaned.columns if col.startswith('PropertyType_')]\n",
    "final_features.extend(property_type_cols)\n",
    "\n",
    "# Ensure all final features actually exist in the DataFrame before selecting X\n",
    "final_features = [f for f in final_features if f in df_cleaned.columns]\n",
    "\n",
    "X = df_cleaned[final_features]\n",
    "y = df_cleaned['Price_Cleaned_INR'] # Use the cleaned price as target\n",
    "\n",
    "print(\"\\nFinal features (X) used for training (and expected in Django prediction):\")\n",
    "print(X.columns.tolist())\n",
    "print(f\"Shape of X: {X.shape}, Shape of y: {y.shape}\")\n",
    "\n",
    "# Store the final feature column names for prediction consistency\n",
    "# This list will be saved and used in the Django app\n",
    "model_feature_columns = X.columns.tolist()\n",
    "print(\"\\nModel expects features in this order:\", model_feature_columns)  #cell4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e234bd11-0de3-4695-9f05-03a6e1472b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set shape: (265676, 8), Testing set shape: (66420, 8)\n"
     ]
    }
   ],
   "source": [
    "# Cell 5: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(f\"\\nTraining set shape: {X_train.shape}, Testing set shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "316fd7c6-d37e-4b06-9365-70bf38cee1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training RandomForestRegressor model...\n",
      "Model training complete.\n"
     ]
    }
   ],
   "source": [
    "# Cell 6: Model Training\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.linear_model import LinearRegression # Uncomment if you want to try Linear Regression\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "# model = LinearRegression() # If you prefer a simpler model\n",
    "\n",
    "print(f\"\\nTraining {type(model).__name__} model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da4019de-371e-4fff-944f-a9abe64991a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation (RandomForestRegressor):\n",
      "Mean Absolute Error (MAE): 5756332.64\n",
      "R-squared (R2): 0.71\n"
     ]
    }
   ],
   "source": [
    "# Cell 7: Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\nModel Evaluation ({type(model).__name__}):\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02d0096d-defa-46b0-aa9b-bf377d9e77f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model saved to: model_artifacts\\price_prediction_model.pkl\n",
      "Location LabelEncoder saved to: model_artifacts\\location_encoder.pkl\n",
      "Furnishing LabelEncoder saved to: model_artifacts\\furnishing_encoder.pkl\n",
      "One-hot encoded columns list saved to: model_artifacts\\one_hot_cols.pkl\n",
      "\n",
      "Training and artifact saving process complete. You can now use these .pkl files in your Django app.\n"
     ]
    }
   ],
   "source": [
    "# Cell 8: Save Model and Encoders\n",
    "ARTIFACTS_DIR = 'model_artifacts' # Ensure this matches your folder name\n",
    "if not os.path.exists(ARTIFACTS_DIR):\n",
    "    os.makedirs(ARTIFACTS_DIR)\n",
    "\n",
    "MODEL_PATH = os.path.join(ARTIFACTS_DIR, 'price_prediction_model.pkl')\n",
    "LOCATION_ENCODER_PATH = os.path.join(ARTIFACTS_DIR, 'location_encoder.pkl')\n",
    "FURNISHING_ENCODER_PATH = os.path.join(ARTIFACTS_DIR, 'furnishing_encoder.pkl')\n",
    "ONE_HOT_COLS_PATH = os.path.join(ARTIFACTS_DIR, 'one_hot_cols.pkl')\n",
    "\n",
    "with open(MODEL_PATH, 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "print(f\"\\nModel saved to: {MODEL_PATH}\")\n",
    "\n",
    "if location_encoder:\n",
    "    with open(LOCATION_ENCODER_PATH, 'wb') as encoder_file:\n",
    "        pickle.dump(location_encoder, encoder_file)\n",
    "    print(f\"Location LabelEncoder saved to: {LOCATION_ENCODER_PATH}\")\n",
    "\n",
    "if furnishing_encoder:\n",
    "    with open(FURNISHING_ENCODER_PATH, 'wb') as encoder_file:\n",
    "        pickle.dump(furnishing_encoder, encoder_file)\n",
    "    print(f\"Furnishing LabelEncoder saved to: {FURNISHING_ENCODER_PATH}\")\n",
    "\n",
    "with open(ONE_HOT_COLS_PATH, 'wb') as cols_file:\n",
    "    pickle.dump(model_feature_columns, cols_file) # Using the model_feature_columns from Cell 4\n",
    "print(f\"One-hot encoded columns list saved to: {ONE_HOT_COLS_PATH}\")\n",
    "\n",
    "print(\"\\nTraining and artifact saving process complete. You can now use these .pkl files in your Django app.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2144a895-93ee-4bcf-8216-ef619169c0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
